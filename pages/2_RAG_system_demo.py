import os
os.environ["CHROMA_SERVER"] = "false"

# SQLite ë²„ì „ ë¬¸ì œ í•´ê²°
import sys
import pysqlite3
sys.modules["sqlite3"] = pysqlite3

# ê·¸ ë‹¤ìŒì— chromadb import
import chromadb
from langchain_community.vectorstores import Chroma

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import json
from datetime import datetime
import time

# Langchain imports
from chromadb.config import Settings  # ì´ ì¤„ì„ íŒŒì¼ ìƒë‹¨ì— ì¶”ê°€
from langchain_community.document_loaders import CSVLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
# from langchain_community.embeddings import HuggingFaceEmbeddings  # ì´ ì¤„ ì œê±°
from langchain_huggingface import HuggingFaceEmbeddings  # ìƒˆë¡œìš´ import
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.documents import Document

# Google API í‚¤ ì„¤ì • - Secrets ìš°ì„ , fallbackìœ¼ë¡œ í•˜ë“œì½”ë”©
os.environ["GOOGLE_API_KEY"] = st.secrets["GOOGLE_API_KEY"]
st.sidebar.success("âœ… API í‚¤ ë¡œë“œ ì„±ê³µ")


# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="AI ì§€ì •í•™ì  ë¦¬ìŠ¤í¬ ì§€ìˆ˜ ë¶„ì„",
    page_icon="ğŸ“Š",
    layout="wide"
)

@st.cache_data
def load_data(file_path):
    """ë°ì´í„° ë¡œë”© í•¨ìˆ˜"""
    try:
        df = pd.read_csv(file_path, encoding='utf-8')
    except UnicodeDecodeError:
        df = pd.read_csv(file_path, encoding='cp949')
    return df

def safe_json_loads(response_str: str, default_value=None):
    """ì•ˆì „í•œ JSON íŒŒì‹±ì„ ìœ„í•œ í—¬í¼ í•¨ìˆ˜"""
    if default_value is None:
        default_value = {}
    try:
        if '```json' in response_str:
            response_str = response_str.split('```json')[1].split('```')[0]
        return json.loads(response_str.strip())
    except (json.JSONDecodeError, IndexError):
        return default_value

def create_improved_analysis_chain():
    """'ìƒê°ì˜ ì‚¬ìŠ¬', 'ìê¸° ë¹„íŒ', 'ê°•ë„' í‰ê°€ë¥¼ í¬í•¨í•˜ì—¬ ì •í™•ë„ë¥¼ ë†’ì¸ ë¶„ì„ ì²´ì¸"""
    prompt_template = ChatPromptTemplate.from_template(
        """
[AI ì‘ì—… ì§€ì¹¨ - ìˆ˜ì…ì ë¦¬ìŠ¤í¬ ë¶„ì„ (ê³ ë„í™” ë²„ì „)]

ë‹¹ì‹ ì€ 'ë¹„ìš©'ê³¼ 'ê³µê¸‰ ì•ˆì •ì„±' ê´€ì ì—ì„œë§Œ í‰ê°€í•˜ëŠ” ëŒ€í•œë¯¼êµ­ ì›ìì¬ êµ¬ë§¤ ë‹´ë‹¹ìì…ë‹ˆë‹¤.
ê°€ê²© ìƒìŠ¹ì´ë‚˜ ê³µê¸‰ë§ ë¶ˆì•ˆì •ì€ ì›ì¸ê³¼ ê´€ê³„ì—†ì´ ë¶€ì •ì  ì‹ í˜¸ì…ë‹ˆë‹¤.

[ë¶„ì„ ì ˆì°¨ (4ë‹¨ê³„)]

### 1ë‹¨ê³„: ì‚¬ì‹¤ ì‹ë³„ (Fact Identification)
- ë¬¸ì¥ì—ì„œ {target_item} ìˆ˜ì…ê³¼ ê´€ë ¨ëœ ê°ê´€ì ì¸ ì‚¬ì‹¤(event)ì„ ë¨¼ì € ì‹ë³„í•©ë‹ˆë‹¤.

### 2ë‹¨ê³„: ì˜í–¥ ë¶„ì„ (Impact Analysis - Chain of Thought)
- ê° ì‚¬ì‹¤ì´ ëŒ€í•œë¯¼êµ­ì˜ {target_item} ìˆ˜ì…ì— ì–´ë–¤ ì—°ì‡„ì ì¸ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ì§€ ë‹¨ê³„ë³„ë¡œ ì¶”ë¡ í•˜ì„¸ìš”.
- (ì˜ˆ: "Aì‚¬ íŒŒì—…" -> "ìƒì‚° ì°¨ì§ˆ ë°œìƒ" -> "ì‹œì¥ ê³µê¸‰ëŸ‰ ê°ì†Œ" -> "ìˆ˜ì… ê°€ê²© ìƒìŠ¹ ì••ë ¥")
- ì´ ì¶”ë¡  ê³¼ì •ì„ 'reason'ì— ëª…í™•íˆ ì„œìˆ í•´ì•¼ í•©ë‹ˆë‹¤.

### 3ë‹¨ê³„: ì´ˆê¸° ë¶„ë¥˜ (Initial Classification)
- 'ì˜í–¥ ë¶„ì„' ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ, í•´ë‹¹ ì‚¬ê±´ì´ ìˆ˜ì…ìì—ê²Œ [Positive], [Negative], [Neutral] ì¤‘ ë¬´ì—‡ì¸ì§€, ê·¸ë¦¬ê³  ê·¸ ì˜í–¥ì˜ ê°•ë„ë¥¼ [High, Medium, Low] ì¤‘ì—ì„œ ì ì •ì ìœ¼ë¡œ íŒë‹¨í•©ë‹ˆë‹¤.

### 4ë‹¨ê³„: ìê¸° ë¹„íŒ ë° ìµœì¢… ê²°ì • (Self-Critique & Final Decision)
- ë‚´ë¦° ì ì • íŒë‹¨ì´ [ìµœì¢… íŒë‹¨ ì›ì¹™]ì— ë¶€í•©í•˜ëŠ”ì§€ ìŠ¤ìŠ¤ë¡œ ê²€í† í•˜ì„¸ìš”.
- (ì˜ˆ: "ì´ ì‚¬ê±´ì€ ê²½ê¸° íšŒë³µ ì‹ í˜¸ë¡œ ë³¼ ìˆ˜ë„ ìˆì§€ë§Œ, ëª…ì‹œì ìœ¼ë¡œ 'ê°€ê²© ìƒìŠ¹'ì„ ìœ ë°œí–ˆìœ¼ë¯€ë¡œ, ìˆ˜ì…ì ê´€ì ì—ì„œëŠ” ìµœì¢…ì ìœ¼ë¡œ [Negative]ë¡œ ë¶„ë¥˜í•˜ëŠ” ê²ƒì´ ì›ì¹™ì— ë§ë‹¤.")
- ì´ ê²€í†  ê³¼ì •ì„ ê±°ì³ ìµœì¢… ë¶„ë¥˜(classification)ì™€ ê°•ë„(intensity)ë¥¼ í™•ì •í•©ë‹ˆë‹¤.

---

[ìµœì¢… íŒë‹¨ ì›ì¹™]
- ğŸš¨ **ê°€ê²© ë³€ë™ ìµœìš°ì„  ì›ì¹™**: 'ê°€ê²© ìƒìŠ¹' ë˜ëŠ” 'ìƒìŠ¹ ì••ë ¥'ì´ ì–¸ê¸‰ë˜ë©´, ë‹¤ë¥¸ ê¸ì •ì  ë§¥ë½(ì˜ˆ: ìˆ˜ìš” ì¦ê°€)ì´ ìˆë”ë¼ë„ ë¬´ì¡°ê±´ [Negative]ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤. ë°˜ëŒ€ë¡œ 'ê°€ê²© í•˜ë½'ì€ [Positive]ì…ë‹ˆë‹¤.
- **ê³µê¸‰ë§ ë¦¬ìŠ¤í¬ ìš°ì„  ì›ì¹™**: ê³µê¸‰ ìì²´ë¥¼ ìœ„í˜‘í•˜ëŠ” 'ì „ìŸ', 'ìˆ˜ì¶œ ì „ë©´ ê¸ˆì§€' ë“±ì€ ê°€ê²©ê³¼ ë¬´ê´€í•˜ê²Œ [Negative]ì´ë©°, ê°•ë„ëŠ” [High]ë¡œ íŒë‹¨í•©ë‹ˆë‹¤.
- **ê³¼ì‰ ì¶”ë¡  ê¸ˆì§€**: ë¬¸ì¥ì— ëª…ì‹œëœ ì‚¬ì‹¤ì—ë§Œ ê·¼ê±°í•©ë‹ˆë‹¤.

---

[ë¶„ì„ ëŒ€ìƒ]
- Target Item: {target_item}
- Context: {context}

---

# ì¶œë ¥ JSON í˜•ì‹:

{{
    "analysis": [
        {{
            "sentence": "ë¶„ì„ ëŒ€ìƒ ë¬¸ì¥ ì›ë³¸",
            "classification": "Positive, Negative, Neutral ì¤‘ í•˜ë‚˜",
            "intensity": "High, Medium, Low ì¤‘ í•˜ë‚˜",
            "reason": "ìœ„ ë¶„ì„ ì ˆì°¨ 2ë‹¨ê³„ì™€ 4ë‹¨ê³„ì— ë”°ë¥¸ ìƒì„¸í•œ íŒë‹¨ ê³¼ì • ì„œìˆ "
        }}
    ],
    "overall_summary": "ì´ë²ˆ ë‹¬ì˜ ê¸ì •/ë¶€ì • ìš”ì¸ë“¤ì„ ì¢…í•©í•˜ì—¬ í•œë‘ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•©ë‹ˆë‹¤."
}}
"""
    )
    
    # API í‚¤ê°€ ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
    if not os.getenv("GOOGLE_API_KEY"):
        st.error("GOOGLE_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        return None
        
    llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash-lite-preview-06-17", temperature=0)
    return prompt_template | llm | StrOutputParser()

def setup_rag_database(df):
    """RAG ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶•"""
    all_docs = []
    
    for _, row in df.iterrows():
        content = str(row.get("ë³´ê³ ì„œ ë‚´ìš©", ""))
        raw_date = str(row.get("ë‚ ì§œ", "")).rstrip()
        
        try:
            if len(raw_date) == 6 and raw_date.isdigit():
                # YYYYMM vs YYMMDD ìë™ ê°ì§€
                potential_year = raw_date[:4]
                potential_month = raw_date[4:6]
                
                if (1900 <= int(potential_year) <= 2100 and 1 <= int(potential_month) <= 12):
                    # YYYYMM í˜•ì‹ (ì˜ˆ: 202301)
                    year_month = raw_date
                else:
                    # YYMMDD í˜•ì‹ (ì˜ˆ: 160111)
                    yy = raw_date[:2]
                    mm = raw_date[2:4]
                    yyyy = f"20{yy}" if int(yy) <= 30 else f"19{yy}"
                    year_month = f"{yyyy}{mm}"
            else:
                year_month = ""
        except:
            year_month = ""
            
        metadata = {
            "ë…„ì›”": year_month,
            "ê´‘ë¬¼": str(row.get("ê´‘ë¬¼ì´ë¦„", "")),
            "source": "uploaded_data"
        }
        
        doc = Document(page_content=content, metadata=metadata)
        all_docs.append(doc)
    
    if not all_docs:
        return None, None
        
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=100)
    splits = text_splitter.split_documents(all_docs)
    
    embedding_model = HuggingFaceEmbeddings(model_name="snunlp/KR-SBERT-V40K-klueNLI-augSTS")
    

    # persist_directory ì œê±°í•˜ì—¬ ì¸ë©”ëª¨ë¦¬ ëª¨ë“œ ì‚¬ìš©
    vectorstore = Chroma.from_documents(
        documents=splits,
        embedding=embedding_model,
    # persist_directory="/tmp/chroma_db" â† ì´ ë¶€ë¶„ ì œê±°
        collection_name=f"rag_collection_{hash(str(splits[:10]))}"
    )
    
    return vectorstore, embedding_model

def get_sentences_from_text_with_llm(text_block: str, llm) -> list[str]:
    """LLMì„ ì´ìš©í•œ ë¬¸ì¥ ë¶„ë¦¬"""
    segment_prompt = ChatPromptTemplate.from_template(
    """
# ì—­í• :
ë‹¹ì‹ ì€ ê¸´ ë³´ê³ ì„œì—ì„œ 'ë‹¨ì¼ ì‚¬ê±´(a single, atomic event)'ì„ ì¶”ì¶œí•˜ì—¬, ê°ê°ì˜ ë…ë¦½ì ì¸ ì˜ë¯¸ë¥¼ ê°€ì§„ ë¬¸ì¥ìœ¼ë¡œ ë¶„ë¦¬í•˜ëŠ” ë¬¸ë§¥ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

# í•µì‹¬ ì§€ì‹œì‚¬í•­:
1. ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ë¥¼ ì˜ë¯¸ì ìœ¼ë¡œ ì™„ì „í•œ í•˜ë‚˜ì˜ ì•„ì´ë””ì–´ë¥¼ ë‹´ê³  ìˆëŠ” ë‹¨ìœ„ë¡œ ë¬¶ê±°ë‚˜ ë‚˜ëˆ ì£¼ì„¸ìš”.

2. **[ë¶„ë¦¬ ì›ì¹™]** í•˜ë‚˜ì˜ ë¬¸ì¥ ì•ˆì— ì ‘ì†ì‚¬(~í–ˆìœ¼ë©°, ~í•˜ê³  ë“±)ë¡œ ì—°ê²°ëœ ì—¬ëŸ¬ ì‚¬ê±´ì´ ìˆë‹¤ë©´, ê°ê°ì˜ **ë…ë¦½ì ì¸ ì‚¬ê±´ìœ¼ë¡œ ë°˜ë“œì‹œ ë¶„ë¦¬**í•´ì•¼ í•©ë‹ˆë‹¤.
   - ì˜ˆì‹œ: "ì¤‘êµ­ì€ Aë¥¼ í–ˆê³ , ë¯¸êµ­ì€ Bë¥¼ í–ˆë‹¤." -> "ì¤‘êµ­ì€ Aë¥¼ í–ˆë‹¤.", "ë¯¸êµ­ì€ Bë¥¼ í–ˆë‹¤."

3. ğŸš¨ **[ë§¤ìš° ì¤‘ìš” - ë³‘í•© ì›ì¹™]** ì´ì™€ ë°˜ëŒ€ë¡œ, **í•˜ë‚˜ì˜ ì‚¬ê±´ì„ ì„¤ëª…í•˜ê¸° ìœ„í•´ ë…¼ë¦¬ì ìœ¼ë¡œ ê°•í•˜ê²Œ ì—°ê²°ëœ ì—¬ëŸ¬ ë¬¸ì¥ì€ ë°˜ë“œì‹œ í•˜ë‚˜ì˜ ì™„ê²°ëœ ë¬¸ì¥ìœ¼ë¡œ í•©ì³ì•¼ í•©ë‹ˆë‹¤.**
   - **ì›ì¸ê³¼ ê²°ê³¼, ì£¼ì¥ê³¼ ê·¼ê±°, í˜„ìƒê³¼ ë¶€ì—° ì„¤ëª…, ëª©ì ê³¼ ìˆ˜ë‹¨** ë“±ì€ ë¶„ë¦¬í•´ì„œëŠ” ì•ˆ ë˜ëŠ” ê°•ë ¥í•œ ì—°ê²° ê´€ê³„ì…ë‹ˆë‹¤.

4. ê° ë‹¨ìœ„ëŠ” ê·¸ ìì²´ë¡œ ë…ë¦½ì ìœ¼ë¡œ ì´í•´ë  ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.

5. ë‹µë³€ì€ ë‹¤ë¥¸ ì–´ë–¤ ì„¤ëª…ë„ ì—†ì´, ì˜¤ì§ JSON í˜•ì‹ì˜ ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”.

# ì¢‹ì€ 'ë³‘í•©' ì˜ˆì‹œ (ì—¬ëŸ¬ ë¬¸ì¥ì„ í•˜ë‚˜ë¡œ í•©ì³ì•¼ í•˜ëŠ” ê²½ìš°):
- ì›ë³¸: "Sherrittç¤¾ëŠ” ë¹„ìš©ì ˆê° ì¡°ì¹˜ì— ì°©ìˆ˜í–ˆìŠµë‹ˆë‹¤. ì¡°ì§ ê°„ì†Œí™”ë¥¼ í†µí•œ ì¸ë ¥ ê°ì¶• ë° ë¹„ìš© ì ˆê° í”„ë¡œê·¸ë¨ì„ ì¶”ì§„í•˜ê³  ìˆìŠµë‹ˆë‹¤."
- ì´ìƒì ì¸ ì¶œë ¥: ["Sherrittì‚¬ëŠ” ë¹„ìš© ì ˆê° ì¡°ì¹˜ì˜ ì¼í™˜ìœ¼ë¡œ, ì¡°ì§ ê°„ì†Œí™”ë¥¼ í†µí•œ ì¸ë ¥ ê°ì¶• í”„ë¡œê·¸ë¨ì„ ì¶”ì§„í•˜ê³  ìˆìŠµë‹ˆë‹¤."]

# ğŸš¨ ì¢‹ì€ 'ë¶„ë¦¬' ì˜ˆì‹œ (í•˜ë‚˜ì˜ ë¬¸ì¥ì„ ì—¬ëŸ¬ ê°œë¡œ ë‚˜ëˆ ì•¼ í•˜ëŠ” ê²½ìš°):
- ì›ë³¸: "ì¤‘êµ­ ìƒë¬´ë¶€ëŠ” ë¯¸êµ­ì˜ ì¸í”Œë ˆì´ì…˜ ê°ì¶•ë²•(IRA) ë³´ì¡°ê¸ˆ ì§€ê¸‰ ëŒ€ìƒì—ì„œ ì¤‘êµ­ì‚° ì „ê¸°ì°¨ë¥¼ ì œì™¸í•œ ê²ƒì— ëŒ€í•´ WTOì— ì œì†Œí–ˆìœ¼ë©°, ì¸ë„ë„¤ì‹œì•„ Nickel Industriesì‚¬ì˜ ë‹ˆì¼ˆ ìƒì‚°ëŸ‰ì€ ì „ë…„ ëŒ€ë¹„ í¬ê²Œ ì¦ê°€í–ˆìŠµë‹ˆë‹¤."
- ì´ìƒì ì¸ ì¶œë ¥: [
    "ì¤‘êµ­ ìƒë¬´ë¶€ëŠ” ë¯¸êµ­ IRAì˜ ì „ê¸°ì°¨ ë³´ì¡°ê¸ˆ ì •ì±…ì— ëŒ€í•´ WTOì— ì œì†Œí–ˆìŠµë‹ˆë‹¤.",
    "ì¸ë„ë„¤ì‹œì•„ Nickel Industriesì‚¬ì˜ ë‹ˆì¼ˆ ìƒì‚°ëŸ‰ì´ ì „ë…„ ëŒ€ë¹„ í¬ê²Œ ì¦ê°€í–ˆìŠµë‹ˆë‹¤."
  ]

# ì´ì œ ì•„ë˜ í…ìŠ¤íŠ¸ë¥¼ ë¶„ë¦¬í•´ì£¼ì„¸ìš”:
{text}
    """
    )
    
    segment_chain = segment_prompt | llm | StrOutputParser()
    response_str = segment_chain.invoke({"text": text_block})
    sentences = safe_json_loads(response_str, default_value=[]) if isinstance(response_str, str) else []
    
    if sentences:
        return sentences
    else:
        return [text_block]

def analyze_monthly_data(vectorstore, analysis_chain, target_mineral, year_month_str):
    """íŠ¹ì • ì›” ë°ì´í„° ë¶„ì„"""
    if not analysis_chain:
        return None, []
        
    llm_for_splitter = ChatGoogleGenerativeAI(model="gemini-2.5-flash-lite-preview-06-17", temperature=0)
    
    # í•´ë‹¹ ì›”ì˜ ë°ì´í„° ê²€ìƒ‰
    filter_dict = {
        "$and": [
            {"ê´‘ë¬¼": {"$eq": target_mineral}},
            {"ë…„ì›”": {"$eq": year_month_str}}
        ]
    }
    
    retrieved_texts = vectorstore.get(where=filter_dict, include=["documents"]).get('documents', [])
    
    if not retrieved_texts:
        return None, []
    
    raw_context_str = "\n\n".join(retrieved_texts)
    all_sentences = get_sentences_from_text_with_llm(raw_context_str, llm_for_splitter)
    
    # ë¬¸ì¥ ë¶„ì„
    all_analysis_results = []
    batch_size = 20
    
    for i in range(0, len(all_sentences), batch_size):
        batch_sentences = all_sentences[i:i + batch_size]
        final_context = "\n".join([f"- {s}" for s in batch_sentences])
        
        try:
            response_str = analysis_chain.invoke({
                "context": final_context,
                "target_item": target_mineral
            })
            response_json = safe_json_loads(response_str)
            
            for item in response_json.get("analysis", []):
                all_analysis_results.append({
                    "text": item.get("sentence"),
                    "classification": item.get("classification"),
                    "intensity": item.get("intensity", "Low"),
                    "reason": item.get("reason", "N/A")
                })
            time.sleep(1)
        except Exception as e:
            st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    # NSI ì ìˆ˜ ê³„ì‚°
    intensity_map = {"High": 3, "Medium": 2, "Low": 1}
    p_weighted_sum = 0
    n_weighted_sum = 0
    
    for item in all_analysis_results:
        classification = item.get("classification")
        intensity_str = item.get("intensity", "Low")
        weight = intensity_map.get(intensity_str, 1)
        
        if classification == "Positive":
            p_weighted_sum += weight
        elif classification == "Negative":
            n_weighted_sum += weight
    
    total_analyzed_count = sum(1 for item in all_analysis_results 
                             if item.get("classification") in ["Positive", "Negative"])
    
    if total_analyzed_count > 0:
        nsi_score = (p_weighted_sum - n_weighted_sum) / (p_weighted_sum + n_weighted_sum)
    else:
        nsi_score = 0.0
    
    return nsi_score, all_analysis_results

def create_monthly_index_chart(df):
    """ì›”ë³„ AI ì§€ìˆ˜ ì°¨íŠ¸ ìƒì„±"""
    fig = go.Figure()
    
    fig.add_trace(go.Scatter(
        x=df['date'],
        y=df['final_supply_demand_index'],
        mode='lines+markers',
        name='AI ì§€ì •í•™ì  ë¦¬ìŠ¤í¬ ì§€ìˆ˜',
        line=dict(color='blue', width=2),
        marker=dict(size=4)
    ))
    
    fig.add_hline(y=50, line_dash="dash", line_color="red", 
                  annotation_text="ê¸°ì¤€ì„ (50)")
    
    fig.update_layout(
        title="ì›”ë³„ AI ì§€ì •í•™ì  ë¦¬ìŠ¤í¬ ì§€ìˆ˜",
        xaxis_title="ë‚ ì§œ",
        yaxis_title="ì§€ìˆ˜",
        template="plotly_white",
        height=500
    )
    
    return fig

def create_demo_data():
    """ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ë°ëª¨ ë°ì´í„° ìƒì„±"""
    # ì‹¤ì œ ë°ì´í„°
    data = [
        ["2018-01-01", 48.30853833, 66.2572],
        ["2018-02-01", 35.70994376, 52.38063],
        ["2018-03-01", 40.99328251, 47.68762],
        ["2018-04-01", 32.15823809, 48.56763],
        ["2018-05-01", 33.00612464, 44.4211],
        ["2018-06-01", 35.97254191, 41.73109],
        ["2018-07-01", 22.87388158, 36.2654],
        ["2018-08-01", 22.70828271, 46.91906],
        ["2018-09-01", 21.75227603, 49.69394],
        ["2018-10-01", 33.72107281, 56.57],
        ["2018-11-01", 51.95780185, 59.52792],
        ["2018-12-01", 63.85931784, 69.12348],
        ["2019-01-01", 45.09565978, 72.45798],
        ["2019-02-01", 32.19951265, 65.48166],
        ["2019-03-01", 35.53526014, 55.47445],
        ["2019-04-01", 45.77399129, 52.35337],
        ["2019-05-01", 52.96013052, 54.2517],
        ["2019-06-01", 52.91600268, 60.77776],
        ["2019-07-01", 36.9126266, 60.04048],
        ["2019-08-01", 28.80366673, 48.03721],
        ["2019-09-01", 27.29606746, 34.50652],
        ["2019-10-01", 16.82657282, 25.11431],
        ["2019-11-01", 52.20227331, 26.65043],
        ["2019-12-01", 42.88224131, 37.25958],
        ["2020-01-01", 46.29867987, 47.78317],
        ["2020-02-01", 49.77218331, 60.25396],
        ["2020-03-01", 34.6890241, 60.75027],
        ["2020-04-01", 26.52550362, 67.99711],
        ["2020-05-01", 30.37710751, 68.4022],
        ["2020-06-01", 22.56849174, 62.48999],
        ["2020-07-01", 18.7330919, 56.98171],
        ["2020-08-01", 6.291914214, 49.70712],
        ["2020-09-01", 17.50595719, 39.97428],
        ["2020-10-01", 18.44355509, 37.74649],
        ["2020-11-01", 14.61262883, 35.00895],
        ["2020-12-01", 19.19167292, 29.32921],
        ["2021-01-01", 9.924368088, 25.78061],
        ["2021-02-01", 15.35632647, 17.26855],
        ["2021-03-01", 17.12032087, 13.15765],
        ["2021-04-01", 22.10754428, 21.45722],
        ["2021-05-01", 21.01290983, 18.40972],
        ["2021-06-01", 32.26048824, 12.08277],
        ["2021-07-01", 20.48203577, 11.29698],
        ["2021-08-01", 20.31609262, 9.066557],
        ["2021-09-01", 13.33105465, 9.075382],
        ["2021-10-01", 7.282059578, 8.793292],
        ["2021-11-01", 13.88703809, 7.901674],
        ["2021-12-01", 21.05767886, 10.1564],
        ["2022-01-01", 12.77927961, 8.811239],
        ["2022-02-01", 0, 7.40131],
        ["2022-03-01", 7.96516306, 6.242335],
        ["2022-04-01", 4.863766428, 6.338374],
        ["2022-05-01", 7.260939289, 8.119097],
        ["2022-06-01", 13.85991594, 7.586575],
        ["2022-07-01", 17.14285429, 9.819112],
        ["2022-08-01", 10.49676893, 16.41854],
        ["2022-09-01", 22.09083839, 16.36708],
        ["2022-10-01", 26.43560626, 16.6371],
        ["2022-11-01", 19.64676546, 17.81524],
        ["2022-12-01", 19.1562461, 11.87035],
        ["2023-01-01", 40.03198834, 9.528951],
        ["2023-02-01", 49.49331019, 9.590902],
        ["2023-03-01", 65.56501064, 13.99419],
        ["2023-04-01", 70.43662738, 19.87834],
        ["2023-05-01", 70.73481021, 18.53535],
        ["2023-06-01", 80.1414394, 25.89551],
        ["2023-07-01", 71.8909434, 29.55088],
        ["2023-08-01", 67.12988031, 27.99848],
        ["2023-09-01", 76.43800505, 30.96962],
        ["2023-10-01", 100, 31.97949],
        ["2023-11-01", 84.09436997, 41.74182],
        ["2023-12-01", 82.84669411, 47.39781],
        ["2024-01-01", 84.55067207, 48.13813],
        ["2024-02-01", 79.16141524, 52.14203],
        ["2024-03-01", 62.53566749, 51.21343],
        ["2024-04-01", 56.29632982, 43.99599],
        ["2024-05-01", 48.64784039, 36.39601]
    ]
    
    # DataFrame ìƒì„±
    demo_df = pd.DataFrame(data, columns=['date', 'ai_risk_index', 'actual_supply_index'])
    demo_df['date'] = pd.to_datetime(demo_df['date'])
    
    return demo_df

def create_interactive_dashboard(demo_df):
    """ì¸í„°ë™í‹°ë¸Œ ëŒ€ì‹œë³´ë“œ ìƒì„±"""
    
    # ë©”ì¸ ë¹„êµ ì°¨íŠ¸
    fig_main = go.Figure()
    
    # AI ë¦¬ìŠ¤í¬ ì§€ìˆ˜ (ì´ˆë¡ìƒ‰ ì ì„ )
    fig_main.add_trace(go.Scatter(
        x=demo_df['date'],
        y=demo_df['ai_risk_index'],
        mode='lines+markers',
        name='AI ì§€ì •í•™ì  ë¦¬ìŠ¤í¬ ì§€ìˆ˜',
        line=dict(color='green', width=2, dash='dot'),
        marker=dict(size=4, color='green', symbol='circle'),
        hovertemplate='<b>AI ë¦¬ìŠ¤í¬ ì§€ìˆ˜</b><br>ë‚ ì§œ: %{x}<br>ì§€ìˆ˜: %{y:.1f}<extra></extra>'
    ))
    
    # ì‹¤ì œ ìˆ˜ê¸‰ì•ˆì •í™” ì§€ìˆ˜ (íŒŒë€ìƒ‰)
    fig_main.add_trace(go.Scatter(
        x=demo_df['date'],
        y=demo_df['actual_supply_index'],
        mode='lines+markers',
        name='ì‹¤ì œ ìˆ˜ê¸‰ì•ˆì •í™” ì§€ìˆ˜',
        line=dict(color='#4169E1', width=3),
        marker=dict(size=5, color='#4169E1'),
        hovertemplate='<b>ì‹¤ì œ ìˆ˜ê¸‰ì•ˆì •í™” ì§€ìˆ˜</b><br>ë‚ ì§œ: %{x}<br>ì§€ìˆ˜: %{y:.1f}<extra></extra>'
    ))
    
    # ê¸°ì¤€ì„  í‘œì‹œ
    fig_main.add_hline(y=50, line_dash="dash", line_color="gray", 
                      annotation_text="ê¸°ì¤€ì„  (50)")
    
    fig_main.update_layout(
        title=" ë‹ˆì¼ˆ AI ë¦¬ìŠ¤í¬ ì§€ìˆ˜ vs ì‹¤ì œ ìˆ˜ê¸‰ì•ˆì •í™” ì§€ìˆ˜ ë¹„êµ",
        xaxis_title="ë‚ ì§œ",
        yaxis_title="ì§€ìˆ˜",
        template="plotly_white",
        height=500,
        hovermode='x unified',
        legend=dict(
            orientation="h",
            yanchor="bottom",
            y=1.02,
            xanchor="right",
            x=1
        )
    )
    
    return fig_main


# Streamlit ì•± ë©”ì¸
def main():
    st.title(" AI ë¦¬ìŠ¤í¬ ì§€ìˆ˜ ë¶„ì„ ì‹œìŠ¤í…œ")
    st.markdown("Gemini 2.5 Flash + RAG ê¸°ìˆ ë¡œ êµ¬í˜„í•œ ì§€ì •í•™ì  ë¦¬ìŠ¤í¬ ë¶„ì„ ì‹œìŠ¤í…œ ì²´í—˜")
    st.markdown("---")
    
    # ë°ëª¨ ë°ì´í„° ìƒì„±
    demo_df = create_demo_data()
    
    # ğŸ“ˆ ì¸í„°ë™í‹°ë¸Œ ëŒ€ì‹œë³´ë“œ ì„¹ì…˜
    st.header(" ### ğŸ”¸ ì‹¤ì‹œê°„ AI ë¦¬ìŠ¤í¬ ë¶„ì„ ëŒ€ì‹œë³´ë“œ")
    
    # ë©”ì¸ ì°¨íŠ¸
    fig_main = create_interactive_dashboard(demo_df)
    st.plotly_chart(fig_main, use_container_width=True)
    st.title("AI ë¦¬ìŠ¤í¬ ì§€ìˆ˜ ë¶„ì„ ì‹œìŠ¤í…œ")
    st.markdown("Gemini 2.5 Flash + RAG ê¸°ìˆ ë¡œ êµ¬í˜„í•œ ì§€ì •í•™ì  ë¦¬ìŠ¤í¬ ë¶„ì„ ì‹œìŠ¤í…œ ì²´í—˜")
    st.markdown("---")
    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    st.sidebar.header("âš™ï¸ ì„¤ì •")
    
    # API í‚¤ëŠ” ì´ë¯¸ í•˜ë“œì½”ë”©ë˜ì–´ ìˆìŒ
    st.sidebar.info("Google API Keyê°€ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
    
    # íŒŒì¼ ì—…ë¡œë“œ
    uploaded_file = st.sidebar.file_uploader(
        "CSV íŒŒì¼ ì—…ë¡œë“œ",
        type=['csv'],
        help="ê´‘ë¬¼_ì£¼ê°„ë™í–¥_í†µí•©.csv íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”"
    )
    
    if uploaded_file is not None:
        # ë°ì´í„° ë¡œë”© (ì—¬ëŸ¬ ì¸ì½”ë”© ì‹œë„)
        try:
            df = pd.read_csv(uploaded_file, encoding='utf-8')
        except UnicodeDecodeError:
            try:
                df = pd.read_csv(uploaded_file, encoding='cp949')
            except UnicodeDecodeError:
                try:
                    df = pd.read_csv(uploaded_file, encoding='euc-kr')
                except UnicodeDecodeError:
                    try:
                        df = pd.read_csv(uploaded_file, encoding='utf-8-sig')
                    except UnicodeDecodeError:
                        st.error("íŒŒì¼ ì¸ì½”ë”©ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. UTF-8, CP949, EUC-KR, UTF-8-SIG í˜•ì‹ìœ¼ë¡œ ì €ì¥ëœ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
                        return
        st.sidebar.success(f"ë°ì´í„° ë¡œë”© ì™„ë£Œ: {len(df)}ê°œ í–‰")
        
        # ê´‘ë¬¼ ì„ íƒ
        minerals = df['ê´‘ë¬¼ì´ë¦„'].unique()
        selected_mineral = st.sidebar.selectbox("ë¶„ì„í•  ê´‘ë¬¼ ì„ íƒ", minerals)
        
        # ë©”ì¸ í™”ë©´
        tab1, tab2, tab3 = st.tabs(["ğŸ“ˆ ì›”ë³„ ì§€ìˆ˜", "ğŸ” ìƒì„¸ ë¶„ì„", "ğŸ“‹ JSON ì¶œë ¥ í˜•ì‹"])
        
        with tab1:
            st.header(f"ğŸ”¸{selected_mineral} ì›”ë³„ AI ì§€ì •í•™ì  ë¦¬ìŠ¤í¬ ì§€ìˆ˜")
            
            if st.button("ì§€ìˆ˜ ìƒì„± ì‹œì‘"):
                if not os.getenv("GOOGLE_API_KEY"):
                    st.error("Google API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                    return
                
                with st.spinner("RAG ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶• ì¤‘..."):
                    vectorstore, _ = setup_rag_database(df)
                
                if vectorstore:
                    with st.spinner("AI ë¶„ì„ ì²´ì¸ ìƒì„± ì¤‘..."):
                        analysis_chain = create_improved_analysis_chain()
                    
                    if analysis_chain:
                        # ì›”ë³„ ë°ì´í„° ë¶„ì„ (YYMMDD -> YYYY-MM í˜•ì‹ìœ¼ë¡œ ë³€í™˜)
                        df['ë‚ ì§œ'] = df['ë‚ ì§œ'].astype(str)
                        # 160111 -> 201601 í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                        def convert_date_format(date_str):
                            date_str = str(date_str).strip()
                            if len(date_str) == 6 and date_str.isdigit():
                                potential_year = date_str[:4]
                                potential_month = date_str[4:6]
                                
                                if (1900 <= int(potential_year) <= 2100 and 1 <= int(potential_month) <= 12):
                                    return date_str  # YYYYMM í˜•ì‹ (202301)
                                else:
                                    # YYMMDD í˜•ì‹ (160111)
                                    yy = date_str[:2]
                                    mm = date_str[2:4]
                                    yyyy = f"20{yy}" if int(yy) <= 30 else f"19{yy}"
                                    return f"{yyyy}{mm}"
                            elif len(date_str) >= 4:
                                return f"20{date_str[:2]}{date_str[2:4]}"
                            else:
                                return date_str
                        
                        df['ë…„ì›”'] = df['ë‚ ì§œ'].apply(convert_date_format)
                        
                        available_months = sorted(df[df['ê´‘ë¬¼ì´ë¦„'] == selected_mineral]['ë…„ì›”'].unique())
                        
                        monthly_results = []
                        progress_bar = st.progress(0)
                        
                        for i, month in enumerate(available_months):
                            st.write(f"ë¶„ì„ ì¤‘: {month[:4]}ë…„ {month[4:6]}ì›”")
                            
                            nsi_score, analysis_results = analyze_monthly_data(
                                vectorstore, analysis_chain, selected_mineral, month
                            )
                            
                            if nsi_score is not None:
                                monthly_results.append({
                                    'date': pd.to_datetime(f"{month}01", format='%Y%m%d'),
                                    'nsi_score': nsi_score,
                                    'month': month,
                                    'analysis_results': analysis_results
                                })
                            
                            progress_bar.progress((i + 1) / len(available_months))
                        
                        if monthly_results:
                            results_df = pd.DataFrame(monthly_results)
                            
                            # í‰í™œí™” ë° ì§€ìˆ˜ ê³„ì‚°
                            results_df['nsi_score_smoothed'] = results_df['nsi_score'].ewm(span=6, adjust=False).mean()
                            
                            valid_scores = results_df['nsi_score_smoothed'].dropna()
                            if not valid_scores.empty:
                                min_val, max_val = valid_scores.min(), valid_scores.max()
                                range_val = max_val - min_val
                                if range_val == 0:
                                    results_df['final_supply_demand_index'] = 50.0
                                else:
                                    results_df['final_supply_demand_index'] = results_df.apply(
                                        lambda row: ((row['nsi_score_smoothed'] - min_val) / range_val) * 100 
                                        if pd.notna(row['nsi_score_smoothed']) else np.nan, axis=1
                                    )
                            
                            # ì°¨íŠ¸ í‘œì‹œ
                            fig = create_monthly_index_chart(results_df)
                            st.plotly_chart(fig, use_container_width=True)
                            
                            # ë°ì´í„° í…Œì´ë¸” í‘œì‹œ
                            st.subheader("ğŸ“Š ì›”ë³„ ì§€ìˆ˜ ë°ì´í„°")
                            display_df = results_df[['date', 'final_supply_demand_index', 'nsi_score']].copy()
                            display_df['date'] = display_df['date'].dt.strftime('%Y-%m')
                            display_df.columns = ['ë‚ ì§œ', 'AI ì§€ìˆ˜', 'NSI ì ìˆ˜']
                            st.dataframe(display_df)
                            
                            # ì„¸ì…˜ ìƒíƒœì— ê²°ê³¼ ì €ì¥
                            st.session_state['monthly_results'] = monthly_results
                
        with tab2:
            st.header("ğŸ”¸ íŠ¹ì • ì›” ìƒì„¸ ë¶„ì„")
            
            if 'monthly_results' in st.session_state:
                months = [result['month'] for result in st.session_state['monthly_results']]
                selected_month = st.selectbox(
                    "ë¶„ì„í•  ì›” ì„ íƒ",
                    months,
                    format_func=lambda x: f"{x[:4]}ë…„ {x[4:6]}ì›”"
                )
                
                if selected_month:
                    month_data = next(
                        (result for result in st.session_state['monthly_results'] 
                         if result['month'] == selected_month), None
                    )
                    
                    if month_data:
                        st.subheader(f"{selected_month[:4]}ë…„ {selected_month[4:6]}ì›” ë¶„ì„ ê²°ê³¼")
                        
                        # ìš”ì•½ ì •ë³´
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("NSI ì ìˆ˜", f"{month_data['nsi_score']:.3f}")
                        with col2:
                            positive_count = sum(1 for item in month_data['analysis_results'] 
                                               if item.get('classification') == 'Positive')
                            st.metric("ê¸ì • ìš”ì¸", positive_count)
                        with col3:
                            negative_count = sum(1 for item in month_data['analysis_results'] 
                                               if item.get('classification') == 'Negative')
                            st.metric("ë¶€ì • ìš”ì¸", negative_count)
                        
                        # ìƒì„¸ ë¶„ì„ ê²°ê³¼
                        st.subheader("ğŸ”¸ ë¶„ì„ ìƒì„¸ ë‚´ìš©")
                        for i, item in enumerate(month_data['analysis_results']):
                            with st.expander(f"ë¶„ì„ {i+1}: {item.get('classification', 'N/A')} ({item.get('intensity', 'N/A')})"):
                                st.write("**ì›ë¬¸:**", item.get('text', ''))
                                st.write("**ë¶„ë¥˜:**", item.get('classification', ''))
                                st.write("**ê°•ë„:**", item.get('intensity', ''))
                                st.write("**ë¶„ì„ ì´ìœ :**", item.get('reason', ''))
            else:
                st.info("ë¨¼ì € 'ì›”ë³„ ì§€ìˆ˜' íƒ­ì—ì„œ ë¶„ì„ì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        
        with tab3:
            st.header("ğŸ”¸create_improved_analysis_chain ì¶œë ¥ JSON í˜•ì‹")
            
            st.code("""
{
    "analysis": [
        {
            "sentence": "ë¶„ì„ ëŒ€ìƒ ë¬¸ì¥ ì›ë³¸",
            "classification": "Positive, Negative, Neutral ì¤‘ í•˜ë‚˜",
            "intensity": "High, Medium, Low ì¤‘ í•˜ë‚˜",
            "reason": "ìƒì„¸í•œ íŒë‹¨ ê³¼ì • ì„œìˆ "
        }
    ],
    "overall_summary": "ì´ë²ˆ ë‹¬ì˜ ê¸ì •/ë¶€ì • ìš”ì¸ë“¤ì„ ì¢…í•©í•˜ì—¬ í•œë‘ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½"
}
            """, language="json")
            
            st.markdown("""
            ### ğŸ”¸ JSON í˜•ì‹ ì„¤ëª…
            
            - **analysis**: ê° ë¬¸ì¥ë³„ ë¶„ì„ ê²°ê³¼ ë°°ì—´
              - **sentence**: ë¶„ì„ëœ ì›ë³¸ ë¬¸ì¥
              - **classification**: ê¸ì •(Positive), ë¶€ì •(Negative), ì¤‘ë¦½(Neutral) ë¶„ë¥˜
              - **intensity**: ì˜í–¥ ê°•ë„ - ë†’ìŒ(High), ì¤‘ê°„(Medium), ë‚®ìŒ(Low)
              - **reason**: AIì˜ íŒë‹¨ ê·¼ê±°ì™€ ì¶”ë¡  ê³¼ì •
            
            - **overall_summary**: í•´ë‹¹ ì›”ì˜ ì „ì²´ì ì¸ ì‹œì¥ ìƒí™© ìš”ì•½
            """)
    
    else:
        st.info("ì‚¬ì´ë“œë°”ì—ì„œ CSV íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")

    # ëŒì•„ê°€ê¸° ë²„íŠ¼
    st.markdown("---")
    if st.button("ğŸ  ë©”ì¸ ëŒ€ì‹œë³´ë“œë¡œ ëŒì•„ê°€ê¸°", use_container_width=True):
        st.switch_page("main.py")

    st.markdown("---")
    st.markdown("""
    <div style="text-align: center; color: #666; padding: 2rem;">
        <p><strong>RAG ê¸°ë°˜ ìƒì„±í˜• AIë¥¼ í™œìš©í•œ ìˆ˜ê¸‰ ë¦¬ìŠ¤í¬ ì˜ˆì¸¡ ëª¨ë¸</strong></p>
        <p>ğŸ† ì‚°ì—…í†µìƒìì›ë¶€ ì œ13íšŒ ê³µê³µë°ì´í„° í™œìš© ì•„ì´ë””ì–´ ê³µëª¨ì „ ì¶œí’ˆì‘</p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
